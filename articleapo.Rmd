---
title: "Article APO"
output: github_document
---

# Pour les archées

### Définition de la variable et affichage des fichiers

```{r}
path <- "~/article-apo/Fichierdesequences"
list.files(path)
data<-read.table(file = "/home/rstudio/article-apo/SraRunTable.txt", header = TRUE, sep=",") # Création de la table de données
```

### Utiliser une colonne des métadonnées pour définir le nom des échantillons

```{r}
fnFs <- sort(list.files(path, pattern="_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq.gz", full.names = TRUE))
print(fnFs)
print(fnRs)
```

```{r}
sample.names <- (data$Sample.Name)
sample.names
```

```{r}
plotQualityProfile(fnFs[1:20])
```

```{r}
plotQualityProfile(fnRs[1:20])
```

### Filtrer et rogner

```{r}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(260,260),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) 
head(out)
```

### Construire un modèle de probabilité d’erreur

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```

```{r}
plotErrors(errF, nominalQ=TRUE)
```

### Application de l’algorithme d’interférence d’échantillon de base aux données de séqences filtrées et découpées

```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```

```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```

```{r}
dadaFs[[1]]
```

### Fusionner les lectures appariées

```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
```

```{r}
plotQualityProfile(filtFs[1:10])
```

```{r}
plotQualityProfile(filtRs[1:10])
```

```{r}
head(mergers[[1]])
```

### Construire une table de séquences

```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

```{r}
table(nchar(getSequences(seqtab)))
```

### Supprimer les chimères

```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
```

```{r}
dim(seqtab.nochim)
```

```{r}
sum(seqtab.nochim)/sum(seqtab)
```

### Suivre les lectures à travers le pipeline

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

### Attribuer une taxonomie 

```{r}
taxa <- assignTaxonomy(seqtab.nochim, "~/article-apo/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
```

```{r}
taxa.print <- taxa 
rownames(taxa.print) <- NULL
head(taxa.print)
```

### Evaluer la précision

```{r}
# Vérifier les noms des lignes de seqtab.nochim
rownames(seqtab.nochim)

# Vérifier la structure complète de l'objet
str(seqtab.nochim)

# Recherche du nom exact
grep("Mock", rownames(seqtab.nochim))
```

```{r}
unqs.mock <- seqtab.nochim
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```

```{r}
mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```

```{r}
# Vérification des types de unqs.mock et mock.ref
class(unqs.mock)
class(mock.ref)

# Vérification de la structure des objets
str(unqs.mock)
str(mock.ref)
```

```{r}
unqs.mock <- unlist(unqs.mock)
```

```{r}
unqs.mock[[1]]  # Accède au premier élément de la liste
```

```{r}
# Vérification que unqs.mock et mock.ref sont des vecteurs de chaînes
unqs.mock <- unlist(unqs.mock)
mock.ref <- unlist(mock.ref)

# sapply et grepl
result <- sum(sapply(unqs.mock, function(x) any(grepl(x, mock.ref))))

# Vérification du résultat
print(result)
```

J'ai utilisé la fonction sapply pour appliquer à tous les éléments et la fonction grepl pour rechercher des motifs (patterns) dans des chaînes de caractères. 

```{r}
# Vérification si le fichier existe à l'emplacement spécifié
file_exists <- file.exists(mock.ref)
print(file_exists)
```

Pour évaluer la précision, il n'y avait que mock.ref qui ne fonctionnait pas. Je pense que c'est parce que je n'ai pas de mock dans la table de séquences. 

### Graphiques

```{r}
data <- data.frame(
  sample.names
)

# Installer et charger le package cluster pour la distance de Gower
install.packages("cluster")
library(cluster)
```

```{r}
library(cluster)
```

```{r}
data[] <- lapply(data, function(x) if(is.character(x)) factor(x) else x)
# Calculer la matrice de distance de Gower
dist_matrix_gower <- daisy(data, metric = "gower")

# Vérifier la matrice de distance
print(dist_matrix_gower)

# Réaliser la PCoA avec cmdscale
pcoa_result <- cmdscale(dist_matrix_gower, k = 2)  # k = 2 pour obtenir 2 dimensions

# Visualiser les résultats de la PCoA
plot(pcoa_result[, 1], pcoa_result[, 2], 
     xlab = "Dimension 1", ylab = "Dimension 2", 
     main = "PCoA", pch = 19)
```

# Pour les Bactéries

### Définition de la variable et affichage des fichiers

```{r}
paths <- "~/article-apo/Fichierdesequencesbacterie"
list.files(paths)
data2<-read.table(file = "/home/rstudio/article-apo/SraRunTable_bact21.csv", header = TRUE, sep=",") # Création de la table de données
```

### Utiliser une colonne des métadonnées pour définir le nom des échantillons

```{r}
fnFbs <- sort(list.files(paths, pattern="_1.fastq.gz", full.names = TRUE))
fnRbs <- sort(list.files(paths, pattern="_2.fastq.gz", full.names = TRUE))
print(fnFbs)
print(fnRbs)
```

```{r}
sample.names2 <- (data2$Sample.Name)
sample.names2  
```

Jusqu'à cette étape tout marchait bien. Seulement quand j'ai commencé à faire les graphiques pour visualiser les profils de qualité, ça a donné un graphique très bizarre. On ne distingue que deux lignes noires avec au milieu une ligne orange. Cette ligne orange semble être les quartiles de la distribution du score de qualité. J'ai voulu vérifier le score de qualité des séquences en les regardant et j'ai remarqué que pour chaque séquence, le score était très bon. En effet, le score de qualité est de 30 avec une probabilité de bases incorrectes de 0,001. 

```{r}
plotQualityProfile(fnFbs[1:20])
```

```{r}
plotQualityProfile(fnRbs[1:20])
```

### Filtrer et rogner

```{r}
filtFbs <- file.path(paths, "filtered", paste0(sample.names2, "_F_filt.fastq.gz"))
filtRbs <- file.path(paths, "filtered", paste0(sample.names2, "_R_filt.fastq.gz"))
names(filtFbs) <- sample.names2
names(filtRbs) <- sample.names2
```

```{r}
summary(filtFbs)
```

Lorsque j'ai lancé la commande pour la filtration avec les paramètres de filtrage standard, tout s'est bien déroulé. 

```{r}
out2 <- filterAndTrim(fnFbs, filtFbs, fnRbs, filtRbs, truncLen=c(260,260),
              maxN=0, maxEE=c(4,4), truncQ=4, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) 
head(out2)
```

### Construire un modèle de probabilité d’erreur

Mais quand j'ai voulu construire le modèle de probabilité d'erreur, deux messages d'erreur sont apparus. Celui-ci indiquait que la fonction getErrors() attend une matrice d'erreurs non vide, mais elle reçoit un objet NULL ou une matrice vide à la place.
Je me suis donc assurée que les séquences de lecture étaient valides et que les fichiers nécessaires étaient correctement importés. 

L'autre message indiquait que l'algorithme ne parvenait pas à estimer les taux d'erreur en raison du manque de données suffisantes. J'ai donc trouvé cela bizarre étant donné le bon score de qualité des séquences. J'ai donc pensé que j'avais coupé trop court les séquences, ce qui empêchait une estimation correcte des taux d'erreur. J'ai donc essayé de jouer avec les paramètres de filtrage standard, en particulier maxEE et truncLen, mais ça n'a rien changé. 

Il se peut donc que les lectures des fichiers FastQ aient des problèmes avec un format incorrect ou un fichier mal formé. Cela empêche alors l'algorithme de générer une matrice d'erreur valable. Je pense donc que le problème vient du format des fichiers car dans la table de données, on peut voir qu'ils se terminent tous différemment. Cependant, je n'ai pas trouvé comment résoudre ce problème. 

```{r}
errF2 <- learnErrors(filtFbs, multithread=TRUE)
```

```{r}
errR2 <- learnErrors(filtRbs, multithread=TRUE)
```

```{r}
plotErrors(errF2, nominalQ=TRUE)
```

J'ai donc voulu voir si les graphiques pour les séquences filtrées étaient, eux aussi, anormaux, même si je n'avais pas réussi à aller jusqu'au bout de la filtration. Sans grande surprise, ils étaient visuellement identiques aux précédents.  

```{r}
plotQualityProfile(filtFbs[1])
```


